# MÃ¤ngelmelder Konstanz - NLP-Analyse mit Coherence Score


**Projekt: Data Analysis (DLBDSEDA02_D)**  
**Autor: Tobias Seekatz**

Automatisierte Identifikation von Problemthemen aus BÃ¼rgerbeschwerden mit **automatischer Topic-Anzahl Optimierung** mittels Coherence Score.

## ðŸŽ¯ Zielsetzung

Analyse unstrukturierter BÃ¼rgerbeschwerden aus dem "MÃ¤ngelmelder Konstanz" zur automatisierten Themenidentifikation. **Neu:** Automatische Bestimmung der optimalen Anzahl von Topics (k) durch Coherence Score (c_v metric).

## âœ¨ Features

### Kern-FunktionalitÃ¤t
- **Datenvorverarbeitung**: Normalisierung, Tokenisierung, Lemmatisierung (spaCy)
- **Vektorisierung**: CountVectorizer (BoW) und TF-IDF
- **Topic Modeling**: Latent Dirichlet Allocation (LDA)
- **N-Gramm-Analyse**: Bigramme fÃ¼r kontextuelle Wortpaare
- **Visualisierungen**: WordCloud, Plots, pyLDAvis

### ðŸ†• Neu: Coherence Score Optimierung
- **Automatische k-Optimierung**: Findet optimale Topic-Anzahl
- **Coherence Score (c_v)**: Evaluiert Themen-KohÃ¤renz mit gensim
- **Visualisierung**: Coherence Score Ã¼ber verschiedene k-Werte
- **Empfehlungssystem**: Interpretation der Coherence-QualitÃ¤t

## ðŸš€ Schnellstart

### Installation

```bash
# 1. Virtual Environment
python -m venv .venv
source .venv/bin/activate  # Mac/Linux
# .venv\Scripts\activate   # Windows

# 2. Dependencies
pip install -r requirements.txt

# 3. spaCy Modell
python -m spacy download de_core_news_sm

# 4. NLTK Daten (optional)
python -c "import nltk; nltk.download('stopwords')"
```

### Daten vorbereiten

```bash
# Kopiere deine CSV-Datei nach:
# data/raw/maengelmelder_konstanz.csv
```

### AusfÃ¼hrung

#### Variante 1: Automatische Topic-Optimierung (Empfohlen)

```bash
python main.py --auto-optimize
```

**Was passiert:**
1. Testet verschiedene Topic-Anzahlen (k=2 bis k=15)
2. Berechnet Coherence Score fÃ¼r jedes k
3. WÃ¤hlt optimales k automatisch
4. FÃ¼hrt vollstÃ¤ndige Analyse durch
5. Speichert Coherence-Plot

#### Variante 2: Nur Optimierung (ohne vollstÃ¤ndige Analyse)

```bash
python main.py --optimize-topics
```

**Empfohlen fÃ¼r:**
- Erste Exploration der Daten
- Schnelle k-Bestimmung
- Vergleich verschiedener DatensÃ¤tze

#### Variante 3: Manuelle Topic-Anzahl

```bash
python main.py --topics 5
```

**Nutze wenn:**
- Du die optimale Anzahl bereits kennst
- Zeitersparnis wichtig ist
- Reproduzierbare Ergebnisse benÃ¶tigt werden

#### Variante 4: Custom Optimierungs-Bereich

```bash
python main.py --auto-optimize --min-topics 3 --max-topics 12
```

### Alle Optionen

```bash
# Hilfe anzeigen
python main.py --help

# Mit eigener CSV
python main.py --input data/raw/meine_daten.csv --auto-optimize

# Custom Range + Verbose
python main.py --auto-optimize --min-topics 2 --max-topics 20 --verbose
```

## ðŸ“Š Verwendungsbeispiele

### Beispiel 1: Standard-Workflow

```bash
# Automatische Optimierung
python main.py --auto-optimize

# Ausgabe:
# Optimale Topic-Anzahl: k=7
# Coherence Score: 0.4523
# (Gute Themen-KohÃ¤renz)
```

### Beispiel 2: Vergleich verschiedener k-Werte

```bash
# Teste breiten Bereich
python main.py --optimize-topics --min-topics 2 --max-topics 20

# Ergebnis:
# coherence_scores.png zeigt Kurve
# topic_optimization.json enthÃ¤lt alle Scores
```

### Beispiel 3: Reproduzierbare Analyse

```bash
# Verwende vorher ermitteltes optimales k
python main.py --topics 7

## ðŸ“ˆ Coherence Score Interpretation

Der Coherence Score (c_v metric) misst die semantische KohÃ¤renz von Topics:

| Score | QualitÃ¤t | Bedeutung |
|-------|----------|-----------|
| **> 0.5** | Exzellent | Sehr kohÃ¤rente, interpretierbare Topics |
| **0.4 - 0.5** | Gut | Klare Themen, gute Interpretierbarkeit |
| **0.3 - 0.4** | Akzeptabel | Brauchbare Themen, teilweise Ã¼berlappend |
| **< 0.3** | Niedrig | Schwache KohÃ¤renz, mehr Daten nÃ¶tig |

**Faktoren die Coherence beeinflussen:**
- Datenmenge (mehr Texte = bessere Scores)
- DatenqualitÃ¤t (saubere Vorverarbeitung wichtig)
- DomÃ¤nen-HomogenitÃ¤t (Ã¤hnliche Themen = hÃ¶here Scores)
- k-Wert (zu viele/wenige Topics senken Score)

## ðŸ“ Output-Struktur

Nach der Analyse:

```
output/
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ coherence_scores.png      # NEU: k-Optimierung
â”‚   â”œâ”€â”€ wordcloud.png
â”‚   â”œâ”€â”€ top_words.png
â”‚   â””â”€â”€ top_bigrams.png
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ lda_interactive.html      # pyLDAvis
â””â”€â”€ analysis/
    â”œâ”€â”€ analysis_results.json     # Haupt-Ergebnisse
    â””â”€â”€ topic_optimization.json   # NEU: Coherence Scores
```

## ðŸ› ï¸ Software-Stack

### Core
- **Python 3.8+**
- **pandas**: Datenmanagement
- **spaCy**: Deutsches NLP & Lemmatisierung
- **scikit-learn**: Vektorisierung & LDA

### Neu: Topic-Optimierung
- **gensim**: Coherence Score Berechnung
- **gensim.models.CoherenceModel**: c_v metric

### Visualisierung
- **matplotlib**: Plots & Diagramme
- **wordcloud**: WordCloud-Erstellung
- **pyLDAvis**: Interaktive Topic-Visualisierung

## ðŸ“– Methodologie

### 1. Datenvorverarbeitung
- Unicode-Normalisierung (NFC)
- Lowercase-Transformation
- Stoppwort-Entfernung (erweiterte deutsche Liste)
- Lemmatisierung (spaCy de_core_news_sm)
- Tokenfilterung (LÃ¤nge, Sonderzeichen)

### 2. Vektorisierung
- **Bag-of-Words (BoW)**: CountVectorizer
  - max_df=0.95 (max. 95% Dokument-Frequenz)
  - min_df=2 (min. 2 Dokumente)
  - max_features=500
- **TF-IDF**: Term Frequency-Inverse Document Frequency

### 3. Topic Modeling
- **Algorithmus**: Latent Dirichlet Allocation (LDA)
- **Optimierung**: Coherence Score (c_v metric)
- **Parameter**: 
  - n_components: 2-15 (auto-optimiert)
  - max_iter: 20
  - random_state: 42 (Reproduzierbarkeit)

### 4. Evaluation
- **Coherence Score (c_v)**: Semantische KohÃ¤renz
- **Perplexity**: Alternative Metrik (Fallback)
- **N-Gramm-Analyse**: Kontextuelle Validierung

## ðŸ”¬ Wissenschaftlicher Kontext

**Coherence Score nach RÃ¶der et al. (2015):**
- Misst menschliche Interpretierbarkeit von Topics
- c_v metric korreliert am besten mit menschlichem Urteil
- Basiert auf word co-occurrence patterns

**Zitat:**
> "Topic coherence measures provide an automatic evaluation of topic quality based on the semantic similarity between high-scoring words in topics."

**Literatur:**
- RÃ¶der, M., Both, A., & Hinneburg, A. (2015). Exploring the Space of Topic Coherence Measures. WSDM '15.
- Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. JMLR.

## ðŸ§ª Testing

```bash
# Installation mit Dev-Dependencies
pip install -r requirements-dev.txt

# Tests ausfÃ¼hren
pytest

# Mit Coverage
pytest --cov=src --cov-report=html
```

## ðŸ“Š Performance

**Laufzeit-Vergleich** (1000 Texte):

| Modus | Laufzeit | k-Werte getestet |
|-------|----------|------------------|
| Manuell (k=5) | ~10 Sekunden | 1 |
| Auto-Optimize (k=2-15) | ~2-3 Minuten | 14 |
| Optimize-Only | ~1-2 Minuten | 14 |

**Empfehlung:**
- Erste Analyse: `--optimize-topics` (schnell, nur k-Bestimmung)
- Produktion: `--topics K` mit ermitteltem k (schnell, reproduzierbar)
- Exploration: `--auto-optimize` (komplett, inkl. k-Optimierung)
